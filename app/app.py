# app/app.py
# File ch√≠nh ƒë·ªÉ ch·∫°y ·ª©ng d·ª•ng web demo b·∫±ng Streamlit.

import sys
import os
import streamlit as st

# Th√™m th∆∞ m·ª•c `src` v√†o Python path ƒë·ªÉ c√≥ th·ªÉ import c√°c module
# S·ª≠ d·ª•ng __file__ c·ªßa ch√≠nh file n√†y ƒë·ªÉ x√°c ƒë·ªãnh ƒë√∫ng PROJECT_ROOT
CURRENT_FILE_DIR = os.path.dirname(os.path.abspath(__file__))
PROJECT_ROOT = os.path.dirname(CURRENT_FILE_DIR)  # L√πi v·ªÅ th∆∞ m·ª•c g·ªëc
if PROJECT_ROOT not in sys.path:
    sys.path.insert(0, PROJECT_ROOT)  # insert(0) ƒë·ªÉ ∆∞u ti√™n t√¨m trong project

# ƒê·ªïi working directory v·ªÅ PROJECT_ROOT ƒë·ªÉ tr√°nh path confusion
os.chdir(PROJECT_ROOT)

from src.inference import NERPredictor
from src import config as ner_config

# Import utils t·ª´ c√πng th∆∞ m·ª•c app
import sys
sys.path.insert(0, CURRENT_FILE_DIR)
from utils import render_entities

@st.cache_resource
def load_ner_model():
    """
    T·∫£i m√¥ h√¨nh NER. S·ª≠ d·ª•ng cache c·ªßa Streamlit ƒë·ªÉ ch·ªâ t·∫£i m·ªôt l·∫ßn.
    Returns:
        NERPredictor: M·ªôt instance c·ªßa l·ªõp NERPredictor, ho·∫∑c None n·∫øu c√≥ l·ªói.
    """
    try:
        print("=" * 80)
        print("DEBUG INFO:")
        print(f"Current working directory: {os.getcwd()}")
        print(f"PROJECT_ROOT: {PROJECT_ROOT}")
        print(f"Model path: {ner_config.MODEL_OUTPUT_DIR}")
        print(f"VnCoreNLP path: {ner_config.VNCORENLP_MODELS_DIR}")
        print("=" * 80)
        
        print("ƒêang t·∫£i m√¥ h√¨nh NER...")
        # B·∫¨T word segmentation ƒë·ªÉ c·∫£i thi·ªán ƒë·ªô ch√≠nh x√°c
        predictor = NERPredictor(
            model_path=ner_config.MODEL_OUTPUT_DIR,
            use_word_segmentation=True
        )
        # Ki·ªÉm tra xem model c√≥ th·ª±c s·ª± ƒë∆∞·ª£c t·∫£i kh√¥ng
        if predictor.model is None:
            return None
        print("T·∫£i m√¥ h√¨nh th√†nh c√¥ng.")
        print(f"Word segmentation: {'Enabled ' if predictor.use_word_segmentation else 'Disabled '}")
        return predictor
    except Exception as e:
        print(f"L·ªñI NGHI√äM TR·ªåNG khi t·∫£i m√¥ h√¨nh: {e}")
        import traceback
        traceback.print_exc()
        return None

def main():
    """H√†m ch√≠nh ch·∫°y ·ª©ng d·ª•ng Streamlit."""
    # --- C·∫•u h√¨nh trang ---
    st.set_page_config(
        page_title="Nh·∫≠n d·∫°ng Th·ª±c th·ªÉ Y t·∫ø",
        page_icon="ü©∫",
        layout="wide"
    )

    # --- Giao di·ªán ng∆∞·ªùi d√πng ---
    st.title("ü©∫ H·ªá th·ªëng Nh·∫≠n d·∫°ng Th·ª±c th·ªÉ Y t·∫ø (NER)")
    st.markdown(
        "Nh·∫≠p m·ªôt c√¢u vƒÉn b·∫£n li√™n quan ƒë·∫øn y t·∫ø (COVID-19) v√†o √¥ b√™n d∆∞·ªõi "
        "v√† nh·∫•n **'Ph√¢n t√≠ch'** ƒë·ªÉ xem c√°c th·ª±c th·ªÉ ƒë∆∞·ª£c m√¥ h√¨nh nh·∫≠n d·∫°ng."
    )
    
    # --- T·∫£i m√¥ h√¨nh ---
    predictor = load_ner_model()

    # --- Ki·ªÉm tra n·∫øu model t·∫£i th·∫•t b·∫°i ---
    if predictor is None:
        st.error(
            f"**L·ªói nghi√™m tr·ªçng khi t·∫£i m√¥ h√¨nh!**\n\n"
            f"Kh√¥ng th·ªÉ t·∫£i m√¥ h√¨nh t·ª´ ƒë∆∞·ªùng d·∫´n: `{os.path.join(PROJECT_ROOT, ner_config.MODEL_OUTPUT_DIR)}`.\n\n"
            "**Vui l√≤ng ki·ªÉm tra:**\n"
            "1. B·∫°n ƒë√£ ch·∫°y script `train.py` th√†nh c√¥ng ch∆∞a?\n"
            "2. Th∆∞ m·ª•c `models/phobert-ner-covid` c√≥ t·ªìn t·∫°i v√† ch·ª©a ƒë·ªß c√°c file c·∫ßn thi·∫øt kh√¥ng?\n"
            "3. Xem l·∫°i c·ª≠a s·ªï Terminal ƒë·ªÉ bi·∫øt th√¥ng b√°o l·ªói chi ti·∫øt."
        )
        # D·ª´ng ·ª©ng d·ª•ng t·∫°i ƒë√¢y
        return

    # √î nh·∫≠p li·ªáu
    default_text = "B·ªánh nh√¢n n·ªØ 35 tu·ªïi, m√£ s·ªë BN2345, qu√™ ·ªü H√† N·ªôi, nh·∫≠p vi·ªán ng√†y 15/08/2021 v·ªõi tri·ªáu ch·ª©ng ho v√† s·ªët."
    user_input = st.text_area("Nh·∫≠p vƒÉn b·∫£n c·ªßa b·∫°n:", default_text, height=200)
    
    # Th√™m th√¥ng tin v·ªÅ word segmentation
    if predictor.use_word_segmentation:
        st.success(" Word Segmentation: **ƒê√£ b·∫≠t** (ƒë·ªÉ c·∫£i thi·ªán ƒë·ªô ch√≠nh x√°c)")
    else:
        st.warning(" Word Segmentation: **Ch∆∞a b·∫≠t** (c√≥ th·ªÉ ·∫£nh h∆∞·ªüng ƒë·ªô ch√≠nh x√°c)")
    
   
    # N√∫t b·∫•m
    if st.button("Ph√¢n t√≠ch", type="primary"):
        if user_input.strip():
            # Hi·ªÉn th·ªã th√¥ng tin v·ªÅ ƒë·ªô d√†i vƒÉn b·∫£n
            char_count = len(user_input)
            word_count = len(user_input.split())
            st.caption(f" ƒê·ªô d√†i: {char_count} k√Ω t·ª±, ~{word_count} t·ª´")
            
            with st.spinner(" ƒêang ph√¢n t√≠ch vƒÉn b·∫£n..."):
                try:
                    # Redirect output ƒë·ªÉ capture progress messages
                    import io
                    from contextlib import redirect_stdout, redirect_stderr
                    
                    # Capture output
                    stdout_capture = io.StringIO()
                    stderr_capture = io.StringIO()
                    
                    with redirect_stdout(stdout_capture), redirect_stderr(stderr_capture):
                        entities = predictor.predict(user_input, show_debug=True)
                    
                    # Hi·ªÉn th·ªã progress messages
                    progress_output = stdout_capture.getvalue()
                    error_output = stderr_capture.getvalue()
                    
                    if progress_output.strip() or error_output.strip():
                        with st.expander(" Chi ti·∫øt x·ª≠ l√Ω", expanded=False):
                            if progress_output.strip():
                                st.text("STDOUT:")
                                st.text(progress_output)
                            if error_output.strip():
                                st.text("STDERR:")
                                st.text(error_output)
                    
                    # Ki·ªÉm tra k·∫øt qu·∫£
                    if entities is None:
                        st.error(" L·ªói: Kh√¥ng th·ªÉ x·ª≠ l√Ω vƒÉn b·∫£n. Vui l√≤ng ki·ªÉm tra log.")
                        return
                    
                    if len(entities) == 0:
                        st.warning(" Kh√¥ng t√¨m th·∫•y th·ª±c th·ªÉ y t·∫ø n√†o trong vƒÉn b·∫£n.")
                        st.info(" **G·ª£i √Ω:**\n"
                               "- Th·ª≠ v·ªõi vƒÉn b·∫£n c√≥ ch·ª©a t√™n b·ªánh vi·ªán, t√™n b·ªánh nh√¢n, ƒë·ªãa ƒëi·ªÉm\n"
                               "- V√≠ d·ª•: 'B·ªánh nh√¢n Nguy·ªÖn VƒÉn A, 35 tu·ªïi, t·∫°i B·ªánh vi·ªán B·∫°ch Mai'")
                    else:
                        st.success(f" Ho√†n t·∫•t! T√¨m th·∫•y {len(entities)} th·ª±c th·ªÉ.")
                        
                        st.subheader("K·∫øt qu·∫£ Nh·∫≠n d·∫°ng:")
                        render_entities(user_input, entities)
                        
                        with st.expander("Xem k·∫øt qu·∫£ d·∫°ng JSON"):
                            st.json(entities)
                            
                except Exception as e:
                    st.error(f" L·ªói khi ph√¢n t√≠ch vƒÉn b·∫£n: {e}")
                    import traceback
                    with st.expander("Chi ti·∫øt l·ªói"):
                        st.code(traceback.format_exc())
        else:
            st.warning("Vui l√≤ng nh·∫≠p vƒÉn b·∫£n ƒë·ªÉ ph√¢n t√≠ch.")

if __name__ == "__main__":
    main()

