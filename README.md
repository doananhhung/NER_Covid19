# Vietnamese NER for COVID-19 Medical Entities using PhoBERT

> **Repository**: [https://github.com/doananhhung/NER\_Covid19](https://github.com/doananhhung/NER_Covid19)

D·ª± √°n n√†y t·∫≠p trung v√†o Nh·∫≠n d·∫°ng Th·ª±c th·ªÉ c√≥ t√™n (Named Entity Recognition - NER) ƒë·ªÉ tr√≠ch xu·∫•t c√°c th·ª±c th·ªÉ y t·∫ø v√† d·ªãch t·ªÖ h·ªçc c·ª• th·ªÉ t·ª´ vƒÉn b·∫£n ti·∫øng Vi·ªát li√™n quan ƒë·∫øn ƒë·∫°i d·ªãch COVID-19. M√¥ h√¨nh ƒë∆∞·ª£c x√¢y d·ª±ng b·∫±ng c√°ch tinh ch·ªânh **PhoBERT**, m·ªôt m√¥ h√¨nh BERT ƒë∆°n ng·ªØ ti√™n ti·∫øn cho ti·∫øng Vi·ªát.

D·ª± √°n bao g·ªìm c√°c script cho kh√°m ph√° d·ªØ li·ªáu, hu·∫•n luy·ªán, ƒë√°nh gi√°, v√† m·ªôt ·ª©ng d·ª•ng web demo ƒë∆°n gi·∫£n s·ª≠ d·ª•ng Streamlit.

## ‚ú® T√≠nh nƒÉng n·ªïi b·∫≠t

  * **NER hi·ªáu su·∫•t cao**: Tinh ch·ªânh PhoBERT (`vinai/phobert-base`) cho t√°c v·ª• NER ti·∫øng Vi·ªát chuy√™n bi·ªát.
  * **Nh·∫≠n d·∫°ng ƒëa th·ª±c th·ªÉ**: X√°c ƒë·ªãnh 10 lo·∫°i th·ª±c th·ªÉ li√™n quan ƒë·∫øn b·ªëi c·∫£nh y t·∫ø v√† COVID-19.
  * **C·∫•u tr√∫c r√µ r√†ng**: Codebase ƒë∆∞·ª£c t·ªï ch·ª©c t·ªët v·ªõi s·ª± ph√¢n t√°ch r√µ r√†ng gi·ªØa c·∫•u h√¨nh, x·ª≠ l√Ω d·ªØ li·ªáu, hu·∫•n luy·ªán v√† suy lu·∫≠n.
  * **T√°i t·∫°o ƒë∆∞·ª£c**: Bao g·ªìm file requirements v√† random seed c·ªë ƒë·ªãnh ƒë·ªÉ ƒë·∫£m b·∫£o k·∫øt qu·∫£ nh·∫•t qu√°n.
  * **Demo t∆∞∆°ng t√°c**: ƒêi k√®m v·ªõi ·ª©ng d·ª•ng web Streamlit ƒë·ªÉ d·ªÖ d√†ng ki·ªÉm tra v√† tr·ª±c quan h√≥a k·∫øt qu·∫£.
  * **H·ªó tr·ª£ Colab**: Cung c·∫•p Jupyter notebook ƒë·ªÉ hu·∫•n luy·ªán m√¥ h√¨nh tr√™n t√†i nguy√™n GPU mi·ªÖn ph√≠ c·ªßa Google Colab.

## üè∑Ô∏è C√°c th·ª±c th·ªÉ ƒë∆∞·ª£c nh·∫≠n d·∫°ng

M√¥ h√¨nh ƒë∆∞·ª£c hu·∫•n luy·ªán ƒë·ªÉ nh·∫≠n d·∫°ng v√† ph√¢n lo·∫°i c√°c th·ª±c th·ªÉ sau:

| Th·∫ª (Tag)                 | M√¥ t·∫£                                     |
| ------------------------- | ----------------------------------------- |
| `PATIENT_ID`              | M√£ s·ªë ƒë·ªãnh danh b·ªánh nh√¢n                 |
| `SYMPTOM_AND_DISEASE`     | Tri·ªáu ch·ª©ng v√† b·ªánh ƒë∆∞·ª£c ƒë·ªÅ c·∫≠p           |
| `LOCATION`                | V·ªã tr√≠ ƒë·ªãa l√Ω (th√†nh ph·ªë, b·ªánh vi·ªán)      |
| `DATE`                    | Ng√†y th√°ng c·ªßa s·ª± ki·ªán (v√≠ d·ª•: ng√†y nh·∫≠p vi·ªán) |
| `ORGANIZATION`            | T·ªï ch·ª©c li√™n quan (v√≠ d·ª•: B·ªô Y t·∫ø)       |
| `AGE`                     | Tu·ªïi c·ªßa b·ªánh nh√¢n                        |
| `GENDER`                  | Gi·ªõi t√≠nh c·ªßa b·ªánh nh√¢n                   |
| `NAME`                    | T√™n c·ªßa c√° nh√¢n                           |
| `TRANSPORTATION`          | Ph∆∞∆°ng ti·ªán di chuy·ªÉn ƒë∆∞·ª£c s·ª≠ d·ª•ng        |
| `JOB`                     | Ngh·ªÅ nghi·ªáp c·ªßa b·ªánh nh√¢n                 |

*Danh s√°ch n√†y ƒë∆∞·ª£c ƒë·ªãnh nghƒ©a trong `src/config.py`.*

## üöÄ H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng cho ng∆∞·ªùi m·ªõi b·∫Øt ƒë·∫ßu

H∆∞·ªõng d·∫´n n√†y d√†nh cho ng∆∞·ªùi ch∆∞a c√≥ kinh nghi·ªám v·ªõi Python ho·∫∑c Machine Learning. H√£y l√†m theo t·ª´ng b∆∞·ªõc m·ªôt c√°ch c·∫©n th·∫≠n.

### B∆∞·ªõc 1: C√†i ƒë·∫∑t Python

**Y√™u c·∫ßu h·ªá th·ªëng:**
  * Python 3.8 ho·∫∑c cao h∆°n
  * √çt nh·∫•t 4GB RAM
  * Kho·∫£ng 2GB dung l∆∞·ª£ng ƒëƒ©a tr·ªëng

**C√†i ƒë·∫∑t Python:**

1. **Windows:**
   - T·∫£i Python t·ª´ [python.org](https://www.python.org/downloads/)
   - Ch·∫°y file c√†i ƒë·∫∑t v√† **QUAN TR·ªåNG**: T√≠ch v√†o √¥ "Add Python to PATH"
   - Nh·∫•n "Install Now"

2. **Ki·ªÉm tra c√†i ƒë·∫∑t:**
   ```bash
   python --version
   ```
   B·∫°n s·∫Ω th·∫•y output nh∆∞: `Python 3.8.10` ho·∫∑c cao h∆°n

### B∆∞·ªõc 2: T·∫£i m√£ ngu·ªìn v·ªÅ m√°y

**C√°ch 1: S·ª≠ d·ª•ng Git (Khuy·∫øn ngh·ªã)**

```bash
# C√†i ƒë·∫∑t Git n·∫øu ch∆∞a c√≥: https://git-scm.com/downloads
git clone https://github.com/doananhhung/NER_Covid19.git
cd NER_Covid19
```

**C√°ch 2: T·∫£i file ZIP**

1. Truy c·∫≠p [https://github.com/doananhhung/NER_Covid19](https://github.com/doananhhung/NER_Covid19)
2. Nh·∫•n n√∫t "Code" > "Download ZIP"
3. Gi·∫£i n√©n file ZIP v√†o th∆∞ m·ª•c b·∫°n mu·ªën

### B∆∞·ªõc 3: T·∫°o m√¥i tr∆∞·ªùng ·∫£o (Virtual Environment)

M√¥i tr∆∞·ªùng ·∫£o gi√∫p c√°ch ly c√°c package Python c·ªßa d·ª± √°n n√†y v·ªõi h·ªá th·ªëng.

```bash
# T·∫°o m√¥i tr∆∞·ªùng ·∫£o
python -m venv venv

# K√≠ch ho·∫°t m√¥i tr∆∞·ªùng ·∫£o
# Tr√™n Windows (CMD):
venv\Scripts\activate

# Tr√™n Windows (PowerShell):
venv\Scripts\Activate.ps1

# Tr√™n Linux/macOS:
source venv/bin/activate
```

**L∆∞u √Ω:** Sau khi k√≠ch ho·∫°t, b·∫°n s·∫Ω th·∫•y `(venv)` xu·∫•t hi·ªán ·ªü ƒë·∫ßu d√≤ng l·ªánh.

### B∆∞·ªõc 4: C√†i ƒë·∫∑t c√°c th∆∞ vi·ªán c·∫ßn thi·∫øt

```bash
# N√¢ng c·∫•p pip l√™n phi√™n b·∫£n m·ªõi nh·∫•t
python -m pip install --upgrade pip

# C√†i ƒë·∫∑t t·∫•t c·∫£ th∆∞ vi·ªán c·∫ßn thi·∫øt
pip install -r requirements.txt
```

**Th·ªùi gian:** Qu√° tr√¨nh n√†y c√≥ th·ªÉ m·∫•t 5-10 ph√∫t t√πy thu·ªôc v√†o t·ªëc ƒë·ªô internet.

### B∆∞·ªõc 5: C√†i ƒë·∫∑t VnCoreNLP (B·∫Øt bu·ªôc)

VnCoreNLP l√† c√¥ng c·ª• t√°ch t·ª´ ti·∫øng Vi·ªát, c·∫ßn thi·∫øt cho m√¥ h√¨nh ho·∫°t ƒë·ªông ch√≠nh x√°c.

```bash
python setup_vncorenlp.py
```

**K·∫øt qu·∫£:** Th∆∞ m·ª•c `vncorenlp_models/` s·∫Ω ƒë∆∞·ª£c t·∫°o ra v·ªõi c√°c file m√¥ h√¨nh b√™n trong.

### B∆∞·ªõc 6: T·∫£i d·ªØ li·ªáu hu·∫•n luy·ªán

**T√πy ch·ªçn A: T·∫£i dataset PhoNER_COVID19**

1. Truy c·∫≠p [PhoNER_COVID19 Dataset](https://github.com/VinAIResearch/PhoNER_COVID19)
2. T·∫£i c√°c file: `train_word.json`, `dev_word.json`, `test_word.json`
3. ƒê·∫∑t v√†o th∆∞ m·ª•c: `data/raw/PhoNER_COVID19/`

**T√πy ch·ªçn B: S·ª≠ d·ª•ng m√¥ h√¨nh ƒë√£ hu·∫•n luy·ªán s·∫µn (Khuy·∫øn ngh·ªã cho ng∆∞·ªùi m·ªõi)**

N·∫øu b·∫°n ch·ªâ mu·ªën d√πng th·ª≠ m√† kh√¥ng mu·ªën hu·∫•n luy·ªán l·∫°i:

1. T·∫£i m√¥ h√¨nh t·ª´: **[Google Drive](https://drive.google.com/drive/folders/1GNf_xUUrswxe3feUWCaTyyLbzFnLfLHS?usp=drive_link)**
2. Gi·∫£i n√©n v√† ƒë·∫∑t th∆∞ m·ª•c `phobert-ner-covid` v√†o `models/`

C·∫•u tr√∫c sau khi ho√†n th√†nh:
```
models/
‚îî‚îÄ‚îÄ phobert-ner-covid/
    ‚îú‚îÄ‚îÄ config.json
    ‚îú‚îÄ‚îÄ model.safetensors
    ‚îú‚îÄ‚îÄ tokenizer_config.json
    ‚îî‚îÄ‚îÄ ... (c√°c file kh√°c)
```

## üõ†Ô∏è H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng chi ti·∫øt

### C√°ch 1: Ch·∫°y ·ª©ng d·ª•ng Web Demo (D·ªÖ nh·∫•t - Khuy·∫øn ngh·ªã cho ng∆∞·ªùi m·ªõi)

ƒê√¢y l√† c√°ch nhanh nh·∫•t ƒë·ªÉ tr·∫£i nghi·ªám m√¥ h√¨nh m√† kh√¥ng c·∫ßn hi·ªÉu v·ªÅ code.

```bash
streamlit run app/app.py
```

**Ho·∫∑c n·∫øu g·∫∑p l·ªói, th·ª≠:**

```bash
streamlit run "d:\ƒë∆∞·ªùng\d·∫´n\ƒë·∫ßy\ƒë·ªß\ƒë·∫øn\app\app.py"
```

**Sau khi ch·∫°y:**
1. Tr√¨nh duy·ªát s·∫Ω t·ª± ƒë·ªông m·ªü (ho·∫∑c truy c·∫≠p `http://localhost:8501`)
2. Nh·∫≠p vƒÉn b·∫£n ti·∫øng Vi·ªát v·ªÅ COVID-19 v√†o √¥ text
3. Nh·∫•n n√∫t "Ph√¢n t√≠ch"
4. Xem k·∫øt qu·∫£ v·ªõi c√°c th·ª±c th·ªÉ ƒë∆∞·ª£c ƒë√°nh d·∫•u m√†u

**V√≠ d·ª• vƒÉn b·∫£n ƒë·ªÉ th·ª≠:**
```
B·ªánh nh√¢n n·ªØ 35 tu·ªïi, m√£ s·ªë BN2345, qu√™ ·ªü H√† N·ªôi, nh·∫≠p vi·ªán ng√†y 15/08/2021 v·ªõi tri·ªáu ch·ª©ng ho v√† s·ªët.
```

**D·ª´ng ·ª©ng d·ª•ng:** Nh·∫•n `Ctrl + C` trong terminal

---

### C√°ch 2: Hu·∫•n luy·ªán m√¥ h√¨nh t·ª´ ƒë·∫ßu (D√†nh cho ng∆∞·ªùi mu·ªën t√πy ch·ªânh)

**L∆∞u √Ω:** C·∫ßn c√≥ d·ªØ li·ªáu hu·∫•n luy·ªán (xem B∆∞·ªõc 6 ph√≠a tr√™n)

#### 2.1. Kh√°m ph√° d·ªØ li·ªáu (T√πy ch·ªçn)

M·ªü notebook ƒë·ªÉ xem th·ªëng k√™ d·ªØ li·ªáu:

```bash
jupyter lab notebooks/Data_Exploration.ipynb
```

#### 2.2. B·∫Øt ƒë·∫ßu hu·∫•n luy·ªán

```bash
python src/train.py
```

**Th·ªùi gian:** 
- V·ªõi CPU: 2-4 gi·ªù
- V·ªõi GPU: 20-30 ph√∫t

**K·∫øt qu·∫£:** M√¥ h√¨nh t·ªët nh·∫•t s·∫Ω ƒë∆∞·ª£c l∆∞u t·∫°i `models/phobert-ner-covid/`

**Theo d√µi qu√° tr√¨nh:**
- Training loss v√† validation F1-score s·∫Ω ƒë∆∞·ª£c in ra sau m·ªói epoch
- M√¥ h√¨nh v·ªõi F1-score cao nh·∫•t tr√™n dev set s·∫Ω ƒë∆∞·ª£c l∆∞u l·∫°i

#### 2.3. T√πy ch·ªânh si√™u tham s·ªë (Hyperparameters)

Ch·ªânh s·ª≠a file `src/config.py`:

```python
# V√≠ d·ª• c√°c tham s·ªë c√≥ th·ªÉ thay ƒë·ªïi:
BATCH_SIZE = 16          # Gi·∫£m n·∫øu thi·∫øu RAM
EPOCHS = 10              # TƒÉng ƒë·ªÉ hu·∫•n luy·ªán l√¢u h∆°n
LEARNING_RATE = 3e-5     # T·ªëc ƒë·ªô h·ªçc
MAX_LEN = 256            # ƒê·ªô d√†i c√¢u t·ªëi ƒëa
```

---

### C√°ch 3: ƒê√°nh gi√° m√¥ h√¨nh tr√™n t·∫≠p test

Sau khi hu·∫•n luy·ªán xong, ƒë√°nh gi√° hi·ªáu su·∫•t:

```bash
python src/evaluate.py
```

**K·∫øt qu·∫£:** B√°o c√°o chi ti·∫øt v·ªõi precision, recall, F1-score cho t·ª´ng lo·∫°i th·ª±c th·ªÉ.

**V√≠ d·ª• output:**
```
              precision    recall  f1-score   support

        NAME       0.95      0.93      0.94       123
         AGE       0.98      0.96      0.97        89
    LOCATION       0.91      0.89      0.90       234
...
```

---

### C√°ch 4: S·ª≠ d·ª•ng m√¥ h√¨nh trong code Python

T·∫°o file Python m·ªõi v√† s·ª≠ d·ª•ng m√¥ h√¨nh nh∆∞ sau:

```python
from src.inference import NERPredictor

# Kh·ªüi t·∫°o predictor
predictor = NERPredictor(
    model_path="models/phobert-ner-covid",
    use_word_segmentation=True  # B·∫≠t t√°ch t·ª´ ti·∫øng Vi·ªát
)

# D·ª± ƒëo√°n
text = "B·ªánh nh√¢n 45 tu·ªïi nh·∫≠p vi·ªán t·∫°i B·ªánh vi·ªán B·∫°ch Mai."
entities = predictor.predict(text)

# In k·∫øt qu·∫£
for entity in entities:
    print(f"{entity['text']} -> {entity['label']}")
```

**Output m·∫´u:**
```
45 tu·ªïi -> AGE
B·ªánh vi·ªán B·∫°ch Mai -> ORGANIZATION
```

---

### C√°ch 5: Ch·∫°y inference nhanh t·ª´ command line

```bash
python src/inference.py
```

Nh·∫≠p vƒÉn b·∫£n tr·ª±c ti·∫øp v√†o terminal v√† nh·∫≠n k·∫øt qu·∫£ ngay l·∫≠p t·ª©c.

---

## üêõ X·ª≠ l√Ω l·ªói th∆∞·ªùng g·∫∑p

### L·ªói 1: "No module named 'torch'"

**Nguy√™n nh√¢n:** Ch∆∞a c√†i ƒë·∫∑t th∆∞ vi·ªán ho·∫∑c ch∆∞a k√≠ch ho·∫°t virtual environment

**Gi·∫£i ph√°p:**
```bash
# K√≠ch ho·∫°t venv
venv\Scripts\activate

# C√†i l·∫°i requirements
pip install -r requirements.txt
```

### L·ªói 2: "FileNotFoundError: models/phobert-ner-covid"

**Nguy√™n nh√¢n:** Ch∆∞a c√≥ m√¥ h√¨nh ƒë√£ hu·∫•n luy·ªán

**Gi·∫£i ph√°p:**
- T·∫£i m√¥ h√¨nh t·ª´ Google Drive (xem B∆∞·ªõc 6 - T√πy ch·ªçn B)
- Ho·∫∑c hu·∫•n luy·ªán m√¥ h√¨nh: `python src/train.py`

### L·ªói 3: "VnCoreNLP models not found"

**Nguy√™n nh√¢n:** Ch∆∞a c√†i ƒë·∫∑t VnCoreNLP

**Gi·∫£i ph√°p:**
```bash
python setup_vncorenlp.py
```

### L·ªói 4: "CUDA out of memory" (Khi hu·∫•n luy·ªán)

**Nguy√™n nh√¢n:** GPU kh√¥ng ƒë·ªß b·ªô nh·ªõ

**Gi·∫£i ph√°p:**
1. Gi·∫£m `BATCH_SIZE` trong `src/config.py` (v√≠ d·ª•: t·ª´ 16 xu·ªëng 8)
2. Ho·∫∑c hu·∫•n luy·ªán tr√™n CPU (ch·∫≠m h∆°n nh∆∞ng ·ªïn ƒë·ªãnh)

### L·ªói 5: Streamlit kh√¥ng ch·∫°y ƒë∆∞·ª£c

**Gi·∫£i ph√°p:**
```bash
# Th·ª≠ v·ªõi ƒë∆∞·ªùng d·∫´n ƒë·∫ßy ƒë·ªß
streamlit run "D:\path\to\your\project\app\app.py"

# Ho·∫∑c ki·ªÉm tra Streamlit ƒë√£ c√†i ƒë·∫∑t ch∆∞a
pip install streamlit --upgrade
```

## üìÇ C·∫•u tr√∫c th∆∞ m·ª•c

```
NER_Covid19/
‚îú‚îÄ‚îÄ app/                      # M√£ ngu·ªìn cho ·ª©ng d·ª•ng web Streamlit
‚îÇ   ‚îú‚îÄ‚îÄ app.py                # Script ch√≠nh c·ªßa ·ª©ng d·ª•ng Streamlit
‚îÇ   ‚îî‚îÄ‚îÄ utils.py              # C√°c h√†m ti·ªán √≠ch cho app (render entities)
‚îú‚îÄ‚îÄ data/                     # D·ªØ li·ªáu dataset
‚îÇ   ‚îú‚îÄ‚îÄ raw/                  # D·ªØ li·ªáu g·ªëc
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ PhoNER_COVID19/   # C√°c file d·ªØ li·ªáu (train, dev, test .json)
‚îÇ   ‚îî‚îÄ‚îÄ processed/            # D·ªØ li·ªáu ƒë√£ x·ª≠ l√Ω (ƒë∆∞·ª£c t·∫°o t·ª± ƒë·ªông)
‚îú‚îÄ‚îÄ models/                   # C√°c checkpoint m√¥ h√¨nh ƒë√£ l∆∞u
‚îÇ   ‚îî‚îÄ‚îÄ phobert-ner-covid/    # M√¥ h√¨nh PhoBERT ƒë√£ fine-tune
‚îú‚îÄ‚îÄ notebooks/                # Jupyter notebooks
‚îÇ   ‚îú‚îÄ‚îÄ Data_Exploration.ipynb           # Kh√°m ph√° v√† ph√¢n t√≠ch d·ªØ li·ªáu
‚îÇ   ‚îî‚îÄ‚îÄ Train_on_Colab_basic.ipynb       # Hu·∫•n luy·ªán tr√™n Google Colab
‚îú‚îÄ‚îÄ src/                      # M√£ ngu·ªìn ch√≠nh
‚îÇ   ‚îú‚îÄ‚îÄ config.py             # C·∫•u h√¨nh t·∫≠p trung v√† si√™u tham s·ªë
‚îÇ   ‚îú‚îÄ‚îÄ dataset.py            # PyTorch Dataset class cho NER
‚îÇ   ‚îú‚îÄ‚îÄ evaluate.py           # Script ƒë√°nh gi√° m√¥ h√¨nh tr√™n t·∫≠p test
‚îÇ   ‚îú‚îÄ‚îÄ inference.py          # Script v√† class ƒë·ªÉ d·ª± ƒëo√°n
‚îÇ   ‚îú‚îÄ‚îÄ text_processor.py     # C√¥ng c·ª• x·ª≠ l√Ω vƒÉn b·∫£n ti·∫øng Vi·ªát (t√°ch t·ª´)
‚îÇ   ‚îî‚îÄ‚îÄ train.py              # Script hu·∫•n luy·ªán ch√≠nh
‚îú‚îÄ‚îÄ vncorenlp_models/         # C√°c m√¥ h√¨nh VnCoreNLP (t·∫£i v·ªÅ b·∫±ng setup script)
‚îÇ   ‚îî‚îÄ‚îÄ models/
‚îÇ       ‚îî‚îÄ‚îÄ wordsegmenter/    # M√¥ h√¨nh t√°ch t·ª´ ti·∫øng Vi·ªát
‚îú‚îÄ‚îÄ .gitignore                # C√°c file b·ªã Git b·ªè qua
‚îú‚îÄ‚îÄ README.md                 # File n√†y
‚îú‚îÄ‚îÄ requirements.txt          # C√°c th∆∞ vi·ªán Python c·∫ßn thi·∫øt
‚îî‚îÄ‚îÄ setup_vncorenlp.py        # Script t·∫£i v·ªÅ c√°c m√¥ h√¨nh VnCoreNLP
```

### Gi·∫£i th√≠ch c√°c file quan tr·ªçng:

| File/Th∆∞ m·ª•c | Ch·ª©c nƒÉng |
|--------------|-----------|
| `src/config.py` | **QUAN TR·ªåNG NH·∫§T** - Ch·ª©a t·∫•t c·∫£ c·∫•u h√¨nh: ƒë∆∞·ªùng d·∫´n, si√™u tham s·ªë, danh s√°ch nh√£n |
| `src/train.py` | Script hu·∫•n luy·ªán m√¥ h√¨nh |
| `src/inference.py` | S·ª≠ d·ª•ng m√¥ h√¨nh ƒë·ªÉ d·ª± ƒëo√°n tr√™n vƒÉn b·∫£n m·ªõi |
| `app/app.py` | ·ª®ng d·ª•ng web demo v·ªõi giao di·ªán ƒë·∫πp |
| `requirements.txt` | Danh s√°ch c√°c th∆∞ vi·ªán c·∫ßn c√†i ƒë·∫∑t |
| `models/phobert-ner-covid/` | M√¥ h√¨nh ƒë√£ hu·∫•n luy·ªán (c·∫ßn t·∫£i v·ªÅ ho·∫∑c t·ª± hu·∫•n luy·ªán) |

## üíª C√¥ng ngh·ªá s·ª≠ d·ª•ng

  * **Th∆∞ vi·ªán c·ªët l√µi**: PyTorch, Transformers, Torch
  * **NLP ti·∫øng Vi·ªát**: py_vncorenlp (t√°ch t·ª´ ti·∫øng Vi·ªát)
  * **X·ª≠ l√Ω d·ªØ li·ªáu**: Pandas
  * **ƒê√°nh gi√°**: seqeval
  * **·ª®ng d·ª•ng Web**: Streamlit

---

## üìö T√†i li·ªáu tham kh·∫£o

- **PhoBERT**: [VinAI Research - PhoBERT](https://github.com/VinAIResearch/PhoBERT)
- **PhoNER_COVID19 Dataset**: [VinAI Research - PhoNER](https://github.com/VinAIResearch/PhoNER_COVID19)
- **VnCoreNLP**: [VnCoreNLP Toolkit](https://github.com/vncorenlp/VnCoreNLP)
- **Transformers**: [Hugging Face Transformers](https://huggingface.co/docs/transformers)

---

## ü§ù ƒê√≥ng g√≥p

M·ªçi ƒë√≥ng g√≥p ƒë·ªÅu ƒë∆∞·ª£c ch√†o ƒë√≥n! N·∫øu b·∫°n mu·ªën c·∫£i thi·ªán d·ª± √°n:

1. Fork repository n√†y
2. T·∫°o branch m·ªõi (`git checkout -b feature/AmazingFeature`)
3. Commit c√°c thay ƒë·ªïi (`git commit -m 'Add some AmazingFeature'`)
4. Push l√™n branch (`git push origin feature/AmazingFeature`)
5. M·ªü Pull Request

---

## üìû Li√™n h·ªá & H·ªó tr·ª£

- **GitHub Issues**: [B√°o l·ªói ho·∫∑c ƒë·ªÅ xu·∫•t t√≠nh nƒÉng](https://github.com/doananhhung/NER_Covid19/issues)
- **Email**: Li√™n h·ªá qua GitHub profile

---

## üìÑ Gi·∫•y ph√©p

D·ª± √°n n√†y ƒë∆∞·ª£c ph√¢n ph·ªëi d∆∞·ªõi gi·∫•y ph√©p MIT. Xem file `LICENSE` ƒë·ªÉ bi·∫øt th√™m chi ti·∫øt.

---

## ‚≠ê L∆∞u √Ω quan tr·ªçng

1. **M√¥ h√¨nh c·∫ßn GPU**: ƒê·ªÉ c√≥ t·ªëc ƒë·ªô t·ªët nh·∫•t khi hu·∫•n luy·ªán, khuy·∫øn ngh·ªã s·ª≠ d·ª•ng GPU. N·∫øu kh√¥ng c√≥ GPU, c√≥ th·ªÉ:
   - S·ª≠ d·ª•ng Google Colab (mi·ªÖn ph√≠) v·ªõi notebook `Train_on_Colab_basic.ipynb`
   - Hu·∫•n luy·ªán tr√™n CPU (ch·∫≠m h∆°n nhi·ªÅu, kho·∫£ng 2-4 gi·ªù)

2. **Word Segmentation**: Lu√¥n b·∫≠t `use_word_segmentation=True` khi s·ª≠ d·ª•ng inference ƒë·ªÉ ƒë·∫°t ƒë·ªô ch√≠nh x√°c cao nh·∫•t.

3. **D·ªØ li·ªáu ri√™ng**: N·∫øu mu·ªën hu·∫•n luy·ªán tr√™n d·ªØ li·ªáu ri√™ng:
   - Format d·ªØ li·ªáu theo chu·∫©n c·ªßa PhoNER_COVID19
   - C·∫≠p nh·∫≠t ƒë∆∞·ªùng d·∫´n trong `src/config.py`
   - ƒêi·ªÅu ch·ªânh danh s√°ch nh√£n (labels) n·∫øu c·∫ßn

4. **RAM y√™u c·∫ßu**: 
   - Hu·∫•n luy·ªán: T·ªëi thi·ªÉu 8GB RAM
   - Inference: T·ªëi thi·ªÉu 4GB RAM

---

## üéØ Quick Start - B·∫Øt ƒë·∫ßu nhanh trong 5 ph√∫t

N·∫øu b·∫°n ch·ªâ mu·ªën th·ª≠ nghi·ªám nhanh:

```bash
# 1. Clone repo
git clone https://github.com/doananhhung/NER_Covid19.git
cd NER_Covid19

# 2. C√†i ƒë·∫∑t
pip install -r requirements.txt
python setup_vncorenlp.py

# 3. T·∫£i m√¥ h√¨nh t·ª´ Google Drive (b·ªè qua n·∫øu mu·ªën t·ª± hu·∫•n luy·ªán)
# Link: https://drive.google.com/drive/folders/1GNf_xUUrswxe3feUWCaTyyLbzFnLfLHS
# Gi·∫£i n√©n v√†o models/phobert-ner-covid/

# 4. Ch·∫°y demo
streamlit run app/app.py
```

**Xong!** Tr√¨nh duy·ªát s·∫Ω m·ªü v√† b·∫°n c√≥ th·ªÉ th·ª≠ nghi·ªám ngay.

---

*C·∫≠p nh·∫≠t l·∫ßn cu·ªëi: October 2025*
